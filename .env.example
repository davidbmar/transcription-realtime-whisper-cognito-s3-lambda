# AWS Configuration
AWS_REGION=us-east-2
AWS_ACCOUNT_ID=your-account-id

# Serverless Service Name (used for resource naming)
SERVICE_NAME=clouddrive-app

# Cognito Configuration (get these from your CloudDrive deployment)
COGNITO_S3_BUCKET=your-s3-bucket-name
COGNITO_DOMAIN=your-cognito-domain
COGNITO_USER_POOL_ID=us-east-2_XXXXXXXXX
COGNITO_USER_POOL_CLIENT_ID=xxxxxxxxxxxxxxxxxx
COGNITO_IDENTITY_POOL_ID=us-east-2:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
COGNITO_API_ENDPOINT=https://xxxxxxxxxx.execute-api.us-east-2.amazonaws.com/dev
COGNITO_CLOUDFRONT_URL=https://xxxxxxxxxxxxx.cloudfront.net

# CloudDrive Browser Testing Credentials
# NOTE: These will be auto-prompted on first run if not set
# The browser-test.js script will save them here automatically
# NEVER commit .env to git - it's in .gitignore
CLOUDDRIVE_TEST_EMAIL=your-email@example.com
CLOUDDRIVE_TEST_PASSWORD=your-password

# Optional: Run browser in headed mode (visible)
# HEADLESS=false

# WhisperLive Configuration (for audio transcription)
# IMPORTANT: Use EDGE BOX architecture (secure, recommended by scripts 030/031)
# - WHISPERLIVE_WS_URL should point to EDGE BOX (public-facing proxy)
# - EDGE_BOX_DNS should be the edge box public IP/DNS
# - GPU_INSTANCE_IP is for internal routing only (edge box -> GPU)
#
# Architecture: Client → wss://EDGE_BOX/ws → ws://GPU:9090
#
# Example with edge box at 3.16.164.228 and GPU at 3.18.106.129:
#   WHISPERLIVE_WS_URL=wss://3.16.164.228/ws  ← Clients connect here
#   EDGE_BOX_DNS=3.16.164.228                 ← Same as edge box IP
#   GPU_INSTANCE_IP=3.18.106.129              ← Internal use only
#
WHISPERLIVE_HOST=your-gpu-internal-ip
WHISPERLIVE_PORT=9090
WHISPERLIVE_WS_URL=wss://your-edge-box-public-ip/ws
EDGE_BOX_DNS=your-edge-box-public-ip
GPU_INSTANCE_IP=your-gpu-internal-ip

# Batch Transcription Configuration
# Used by scripts/515-run-batch-transcribe.sh for optimized parallel processing
#
# Performance Tuning:
# - BATCH_SIZE: Number of chunks to process in a single batch (default: 100)
#   * Higher = fewer model reloads, faster total time
#   * Lower = more frequent progress updates, easier to debug
#   * Recommended: 100 for production, 10 for testing
#
# - BATCH_MAX_PARALLEL_*: Concurrent S3 operations (default: 20)
#   * Higher = faster downloads/uploads, more system resources
#   * Lower = more conservative, safer for resource-constrained systems
#   * AWS S3 limit: ~5,500 requests/second per prefix
#   * Recommended: 20-40 depending on available memory/network
#
# - BATCH_DOWNLOAD_THRESHOLD: When to start GPU processing (default: 30)
#   * Batches <30: Wait for all downloads (minimize transfer overhead)
#   * Batches ≥30: Start GPU after 30 files (faster startup)
#
# - WHISPER_MODEL: Accuracy vs speed trade-off
#   * tiny.en (39M params): 4-5x faster, lower accuracy
#   * base.en (74M params): 2-3x faster, good accuracy [RECOMMENDED]
#   * small.en (244M params): Baseline speed, better accuracy [DEFAULT]
#   * medium.en (769M params): 2x slower, best accuracy
#
# - WHISPER_COMPUTE_TYPE: Precision vs speed
#   * int8: ~2x faster, minimal accuracy loss [RECOMMENDED FOR SPEED]
#   * int8_float16: 1.5x faster, hybrid approach
#   * float16: Baseline speed [DEFAULT]
#   * float32: Slower, no benefit
#
# Example configurations:
#   Fastest (2-3x speedup): WHISPER_MODEL=base.en, WHISPER_COMPUTE_TYPE=int8
#   Balanced: WHISPER_MODEL=small.en, WHISPER_COMPUTE_TYPE=int8 [DEFAULT]
#   Best Quality: WHISPER_MODEL=medium.en, WHISPER_COMPUTE_TYPE=int8
#
BATCH_SIZE=100
BATCH_MAX_PARALLEL_DOWNLOAD=20
BATCH_MAX_PARALLEL_UPLOAD=20
BATCH_DOWNLOAD_THRESHOLD=30
BATCH_DOWNLOAD_TIMEOUT=60
WHISPER_MODEL=small.en
WHISPER_COMPUTE_TYPE=int8

# GPU Configuration for Batch Processing
GPU_INSTANCE_ID=your-gpu-instance-id      # EC2 instance ID (i-xxxxx)
GPU_SSH_KEY_PATH=/home/ubuntu/.ssh/your-key.pem
GPU_HOURLY_COST=0.526                      # g4dn.xlarge on-demand pricing

# Smart Batch Scheduler Configuration
# Used by scripts/535-smart-batch-scheduler.sh for automated GPU management
#
# Threshold-based scheduling:
# - BATCH_THRESHOLD: Min chunks to trigger GPU startup (default: 100)
#   * Higher = fewer GPU startups, more efficient per session
#   * Lower = more responsive, shorter queue wait times
#   * Recommended: 100 for production, 50 for testing
#
# - BATCH_SCHEDULER_CHECK_HOURS: How often to check queue (default: 2)
#   * Used by cron/systemd timer
#   * More frequent = more responsive, more API calls
#   * Less frequent = more efficient, longer wait times
#
# - BATCH_MAX_RUNTIME_HOURS: Safety cutoff (default: 2)
#   * Prevents runaway processes
#   * Should be > expected max batch duration
#
BATCH_THRESHOLD=100
BATCH_SCHEDULER_CHECK_HOURS=2
BATCH_MAX_RUNTIME_HOURS=2

# Google Docs Integration (optional)
# Used by .claude/skills/google-docs-edit/ and scripts/505-*, 510-*
GOOGLE_DOC_ID=your-google-doc-id-here
GOOGLE_CREDENTIALS_PATH=/path/to/credentials.json  # Defaults to google-docs-test/credentials.json
GOOGLE_CREDENTIALS_BASE64=  # Base64-encoded credentials.json for Lambda (auto-generated by script 510)
